{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tools You (Probably) Won't Need to Use.",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vuc7IAFTAJ-8",
        "cellView": "form"
      },
      "source": [
        "#@title silence tensorflow because nobody needs errors :P\n",
        "!pip install silence-tensorflow\n",
        "from silence_tensorflow import silence_tensorflow\n",
        "from google.colab import output\n",
        "silence_tensorflow()\n",
        "output.clear()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG6_Chym4ZH0"
      },
      "source": [
        "# Tools You (Probably) Won't Need to Use.\n",
        "---\n",
        "by Chloe-Noelle\n",
        "\n",
        "A (wip) collection of tools I personally have no need for, but decided to implement for other people, who will most likely have no need for either. Why? Because I hate myself, and most importantly, I hate you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIuDAJTJIsE9"
      },
      "source": [
        "### 1. Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQODwYaD6Rz7",
        "cellView": "form",
        "outputId": "79f5b358-93bf-49fc-b2bc-8618500dcee8"
      },
      "source": [
        "#@title Semantic Arithmetic with Word2Vec\n",
        "#@markdown With Gensim's Word2Vec, a dense vector is formed for every word it knows, with that vector we can do arithmetic, and find the closest vector to the result, and return the coresponding word.\n",
        "#@markdown <br> Subtracting two words will leave the resulting vector too small to be meaningful, try calculating the average of two instead. <br>\n",
        "#@markdown Wrap words in brackets like these \"<word\\>\"\n",
        "#@markdown <br> Then you can treat them like numbers, use any number of subtraction multiplication or addition signs between them to perform arithmetic on them.\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "import gensim.downloader as api\n",
        "\n",
        "#@markdown toggle to avoid reloading model\n",
        "semantic_model_loaded = False #@param {\"type\":\"boolean\"}\n",
        "if(semantic_model_loaded != True):\n",
        "    print(\"Loading Word Embeddings..\")\n",
        "    # glove-wiki-gigaword-100 glove-twitter-25\n",
        "    embeddings = api.load(\"glove-wiki-gigaword-100\")\n",
        "expression = \"(\\u003Cking>+\\u003Clady>)/2\"#@param {\"type\":\"string\"}\n",
        "\n",
        "def parse_semantic_expression(expression=expression):\n",
        "\n",
        "    # Split words and find their embeddings\n",
        "    a = expression.replace(\"<\", \"embeddings['\").replace(\">\",\"']\")\n",
        "    alphabet = \"abcdefghijklmnopqrstuvwxyz'\\\" ->\"\n",
        "    clean = []\n",
        "    for i in expression:\n",
        "        if i in alphabet:\n",
        "            clean.append(i)\n",
        "    clean = ''.join(clean).split(\">\")[:-1]\n",
        "    words = embeddings.similar_by_vector(eval(a), topn=10)\n",
        "\n",
        "    # Remove words if they are part of the expression.\n",
        "    new_words = []\n",
        "    for i in words:\n",
        "        clear = True\n",
        "        for j in clean:\n",
        "            if j in i:\n",
        "                 clear = False \n",
        "        if(clear):\n",
        "            new_words.append(i)\n",
        "    return new_words\n",
        "print(\"Potential Matches and their Coresponding Score\")\n",
        "print('\\n'.join([str(i) for i in parse_semantic_expression()]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Word Embeddings..\n",
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "Potential Matches and their Coresponding Score\n",
            "('queen', 0.8334094882011414)\n",
            "('prince', 0.7351105213165283)\n",
            "('son', 0.7202234268188477)\n",
            "('elizabeth', 0.7183598279953003)\n",
            "('father', 0.708275556564331)\n",
            "('brother', 0.7076902389526367)\n",
            "('daughter', 0.7042185068130493)\n",
            "('uncle', 0.6902905702590942)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oekF4KaoGP0B",
        "cellView": "form"
      },
      "source": [
        "#@title Markov Chain Text Generation\n",
        "#@markdown Definition of Markov Chain from [analyticsindiamag.com](https://analyticsindiamag.com/hands-on-guide-to-markov-chain-for-text-generation/)\n",
        "#@markdown <br> \"Markov chains are random determined processes with a finite set of states that move from one state to another. These sets of transitions from state to state are determined by some probability distribution.\"\n",
        "import numpy as np\n",
        "#@markdown the input text to build the model on\n",
        "# I actually know barely anything about this code i stole it\n",
        "input_text = \"I'm a little teapot, Short and stout, Here is my handle Here is my spout When I get all steamed up, Hear me shout, Tip me over and pour me out!  I'm a very special teapot, Yes, it's true, Here's an example of what I can do, I can turn my handle into a spout, Tip me over and pour me out!\" #@param {\"type\":\"string\"}\n",
        "corpus = input_text.split()\n",
        "def make_pairs(corpus):\n",
        "    for i in range(len(corpus)-1):\n",
        "        yield (corpus[i], corpus[i+1])\n",
        "        \n",
        "pairs = make_pairs(corpus)\n",
        "word_dict = {}\n",
        "for word_1, word_2 in pairs:\n",
        "    if word_1 in word_dict.keys():\n",
        "        word_dict[word_1].append(word_2)\n",
        "    else:\n",
        "        word_dict[word_1] = [word_2]\n",
        "first_word = np.random.choice(corpus)\n",
        "chain = [first_word]\n",
        "#@markdown the number of words to \"generate\" from the model\n",
        "n_words = 20#@param\n",
        "for i in range(n_words):\n",
        "    chain.append(np.random.choice(word_dict[chain[-1]]))\n",
        "' '.join(chain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlRZV_-8It20"
      },
      "source": [
        "### 2. Numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fZAbJg9z_5M",
        "cellView": "form"
      },
      "source": [
        "#@title Compute Optimal Score to End A Turn at when Playing Pig with an N-Sided Die\n",
        "#@markdown I got the idea from [this video](https://youtu.be/ULhRLGzoXQ0). <br>\n",
        "#@markdown Pig is a game played with a die, you roll as many times as you want, you rack up as many points as possible until you either decide to stop, or you roll a 1. If you roll a 1 then you lose all the points for that turn.\n",
        "#@markdown <br> At the end of your turn you add all the points from previous turns and that's your score. You can play against someone and set a goal, or play alone.\n",
        "#@markdown <br> This uses a score-based turn stopping approach (not perfect, but best simple way to strategize).\n",
        "#@markdown <br> you input the number of sides on the die you're using, and you get the score at which if you get above or equal, you should stop rolling because of diminishing returns and a higher probability of rolling a 1 and losing your points.\n",
        "#@markdown <br> I've added the feature to specify the amount of different rolls that can take away your points (`sides_that_zero_your_score`), because you may want to customize the game to your liking.\n",
        "#@markdown <br> <br> Obviously using 2 players to find an optimal score is much harder and requires extensive game theory, but this is a good start.\n",
        "from sympy import *\n",
        "init_printing()\n",
        "\n",
        "num_sides =  6#@param\n",
        "sides_that_zero_your_score =  1#@param\n",
        "def search_pig(num_sides=num_sides, sides_that_zero_your_score=sides_that_zero_your_score):\n",
        "    var('n')\n",
        "    # find the average score\n",
        "    avscore = round(sum(range(num_sides+2)[2:])/num_sides)\n",
        "\n",
        "    # solve inequality\n",
        "    return str(solve(((num_sides-sides_that_zero_your_score)/num_sides)*(avscore+n)>n)).split('<')[-1].replace(\")\", \"\").replace(\" \", \"\")\n",
        "print('For a game of Pig using a {} sided die with {} zero(s),'.format(num_sides, sides_that_zero_your_score))\n",
        "print(\"End your turn when your score is less-than/around {}\".format(search_pig()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0EBywhcKfEc"
      },
      "source": [
        "### Visual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br1TUtAiccAW",
        "cellView": "form"
      },
      "source": [
        "#@title Generate Perlin Noise Field\n",
        "#@markdown What is perlin noise? Idk https://en.wikipedia.org/wiki/Perlin_noise\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "#@markdown shape is width x height\n",
        "shape = \"400x400\" #@param {\"type\":\"string\"}\n",
        "scale = 1#@param\n",
        "\n",
        "def perlin_noise(shape, scale):\n",
        "    # find height and width\n",
        "    height = int(shape.split(\"x\")[0])\n",
        "    width = int(shape.split(\"x\")[1])\n",
        "\n",
        "    # layer different scales of noise on top of eachother\n",
        "    noise_layers = np.array([np.random.random((width,height))*50 for (width,height) in [(int(width/16*scale), int(height/16*scale)), (int(width/8*scale), int(height/8*scale)), (int(width/4*scale), int(height/4*scale)), (int(width), int(height))]])\n",
        "    noise_resize = [np.array(Image.fromarray(np.array(i, dtype=np.uint8)).resize((height,width))) for i in noise_layers]\n",
        "\n",
        "    # add them all together (despite it being avg, i know, im lazy with renaming)\n",
        "    noise_avg = noise_resize[0]\n",
        "    for i in range(len(noise_resize[1:])): noise_avg=noise_avg+noise_resize[i]\n",
        "    noise_avg=noise_avg\n",
        "\n",
        "    return Image.fromarray(np.array(noise_avg, dtype=np.uint8))\n",
        "perlin_noise(shape,scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR1dto9fKkll",
        "cellView": "form"
      },
      "source": [
        "#@title Fire/Fireball Simulation\n",
        "from PIL import Image, ImageFilter, ImageDraw\n",
        "import numpy as np\n",
        "!rm -r frames\n",
        "from google.colab import output\n",
        "#@markdown you have to run the previous cell to have the function for the required perlin noise for this to work <br>\n",
        "#@markdown details of sim explained [here](https://web.archive.org/web/20160418004150/http://freespace.virgin.net/hugo.elias/models/m_fire.htm)\n",
        "#@markdown <br> shape = width x height\n",
        "shape = \"400x400\"#@param {\"type\":\"string\"}\n",
        "width = int(shape.split(\"x\")[1])\n",
        "height = int(shape.split(\"x\")[0])\n",
        "fire_shape = \"fireball\" #@param [\"normal\", \"fireball\"]\n",
        "\n",
        "# create cooling map from function above (or download one)\n",
        "# !wget https://web.archive.org/web/20160418004150im_/http://freespace.virgin.net/hugo.elias/models/coolmap.jpg -O coolmap.jpg\n",
        "# cooling_map = np.array(Image.open(\"coolmap.jpg\").resize((height, width)).convert(\"RGB\"))*0.1\n",
        "flame_scale = 0.16 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "cooling_map = np.array(perlin_noise(shape,1-flame_scale).convert(\"RGB\"))*0.5\n",
        "\n",
        "# create a folder called frames to save the rendered frames to\n",
        "!mkdir frames\n",
        "\n",
        "# the main flame class\n",
        "class flame:\n",
        "    def __init__(self, height, width, cooling_map):\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "\n",
        "        # the simulation itself\n",
        "        self.sim = np.zeros((height,width,3))\n",
        "        self.cooling_map = cooling_map\n",
        "\n",
        "    # scroll the image up and re-draw the source of the flame\n",
        "    def Convection(self):\n",
        "        width_of_bar = 3\n",
        "        self.sim = self.sim[width_of_bar:]\n",
        "        for bar in range(width_of_bar):\n",
        "            if(fire_shape==\"normal\"):\n",
        "                self.sim = np.append(self.sim, np.array([np.ones(self.sim[-1].shape)*255]), axis = 0)\n",
        "            else:\n",
        "                self.sim = np.append(self.sim, np.array([np.zeros(self.sim[-1].shape)]), axis = 0)\n",
        "                image = Image.fromarray(np.array(self.sim, dtype=np.uint8))\n",
        "                draw = ImageDraw.Draw(image)\n",
        "                x = int(width/2)\n",
        "                y = int(height/2)+int(height/4)\n",
        "                r = int(min([height,width])/6)\n",
        "                leftUpPoint = (x-r, y-r)\n",
        "                rightDownPoint = (x+r, y+r)\n",
        "                twoPointList = [leftUpPoint, rightDownPoint]\n",
        "                draw.ellipse(twoPointList, fill=(255,255,255))\n",
        "                self.sim = np.array(image)\n",
        "\n",
        "    # blur the image to simulate fire spread\n",
        "    def Spread(self):\n",
        "        self.sim = np.array(Image.fromarray(np.array(self.sim, dtype=np.uint8)).filter(ImageFilter.BLUR))\n",
        "    \n",
        "    # simulate cooling by dimming the image by the cooling map\n",
        "    def Cooling(self):\n",
        "        flame_height = 0.91 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "        self.sim=self.sim-self.cooling_map*(1-flame_height)\n",
        "        self.sim[self.sim < 0] = 0\n",
        "\n",
        "        # scroll cooling map\n",
        "        buffer_map = self.cooling_map \n",
        "        self.cooling_map = self.cooling_map[1:]\n",
        "        self.cooling_map = np.append(self.cooling_map, [buffer_map[0]], axis=0)\n",
        "    \n",
        "    # save a specific frame\n",
        "    def Render(self, iteration):\n",
        "        Image.fromarray(np.array(self.sim, dtype=np.uint8)).save(\"frames/{}.png\".format(str(iteration).rjust(4, \"0\")))\n",
        "output.clear()\n",
        "\n",
        "# Combine all processes together to create final simulation render\n",
        "spread = 1 \n",
        "frames = 200#@param\n",
        "f = flame(width,height,cooling_map)\n",
        "f.sim[-1]=np.ones(f.sim[-1].shape)*255\n",
        "for i in range(frames):\n",
        "    for step_scale in range(2):\n",
        "        for s in range(spread):\n",
        "            f.Spread()\n",
        "        f.Convection()\n",
        "        f.Cooling()\n",
        "    f.Render(i)\n",
        "\n",
        "# Compile frames as a video\n",
        "!ffmpeg -i \"frames/%04d.png\" out.mp4 -y -r 60\n",
        "output.clear()\n",
        "\n",
        "# Display Video\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('out.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QANYN7W959Vx",
        "cellView": "form"
      },
      "source": [
        "#@title Draw/Classify Written digit & Train MNIST Classifying Model (TF)\n",
        "#@markdown This trains a small Feed Forward network on the MNIST Written Digits dataset. It can classify between numbers 0-9 with around 95% accuracy within just 3 epochs. <br>\n",
        "\n",
        "#@markdown Untick this box if you've already trained it\n",
        "train_model = True #@param{\"type\":\"boolean\"}\n",
        "if(train_model):\n",
        "    import tensorflow as tf\n",
        "    import tensorflow_datasets as tfds\n",
        "    (ds_train, ds_test), ds_info = tfds.load(\n",
        "        'mnist',\n",
        "        split=['train', 'test'],\n",
        "        shuffle_files=True,\n",
        "        as_supervised=True,\n",
        "        with_info=True,\n",
        "    )\n",
        "    def normalize_img(image, label):\n",
        "        \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "        return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "    ds_train = ds_train.map(\n",
        "        normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    ds_train = ds_train.cache()\n",
        "    ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "    ds_train = ds_train.batch(256)\n",
        "    ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    ds_test = ds_test.map(\n",
        "        normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    ds_test = ds_test.batch(256)\n",
        "    ds_test = ds_test.cache()\n",
        "    ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.GaussianNoise(0.1),\n",
        "    tf.keras.layers.Dense(256,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(128,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "    # model.summary()\n",
        "    model.fit(\n",
        "        ds_train,\n",
        "        epochs=4,\n",
        "        batch_size=1024,\n",
        "        validation_data=ds_test,\n",
        "    )\n",
        "\n",
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<canvas width=%d height=%d></canvas>\n",
        "<button>Finish</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "ctx.lineWidth = %d\n",
        "ctx.strokeStyle=\"#FFFFFF\";\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "def draw(filename='drawing.png', w=280, h=280, line_width=10):\n",
        "  display(HTML(canvas_html % (w, h, line_width)))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "#   return len(binary)\n",
        "print(\"Draw on this board!\")\n",
        "draw()\n",
        "print(\"Classifying..\")\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "digit = ImageOps.grayscale(Image.open(\"drawing.png\"))\n",
        "digit = np.array(digit.resize((28,28)))\n",
        "pred = model.predict((np.array([digit])/255))\n",
        "pred = pred[0].tolist()\n",
        "print(\"#-*\"*20)\n",
        "print(\"#\"*20, \"I predict... {}!\".format(pred.index(max(pred))), \"#\"*20)\n",
        "print(\"#-*\"*20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "cellView": "form",
        "id": "hrJrxFKQhvxK",
        "outputId": "0cded7a6-7855-4899-fcac-b30179fade65"
      },
      "source": [
        "#@title Play Pictionary with CLIP\n",
        "#@markdown in this game, you're given a word. You have to draw the word to the best of your ability, and then that drawing will be scored by OpenAI's model CLIP based on how well you did. If you did good enough, you get a point! Otherwise, you lose a point.\n",
        "#@markdown <br> You can input a string of words, separated with commas, for categories to play in. You can also specify how many rounds till game over.\n",
        "import subprocess\n",
        "from google.colab import output\n",
        "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "else:\n",
        "    torch_version_suffix = \"+cu110\"\n",
        "! pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex\n",
        "output.clear()\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import imageio\n",
        "from IPython import display\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "import glob\n",
        "%cd /content/\n",
        "!git clone https://github.com/openai/CLIP.git\n",
        "%cd /content/CLIP/\n",
        "!pip install ftfy\n",
        "import clip\n",
        "import numpy as np\n",
        "# Load the model\n",
        "# perceptor, preprocess = clip.load('ViT-B/32', jit=False)\n",
        "output.clear()\n",
        "\n",
        "!git clone https://github.com/kingchloexx/CLIP-Image-Classification # if not in a notebook, run in console (w/o the \"!\")\n",
        "import os\n",
        "os.chdir(\"CLIP-Image-Classification\")\n",
        "\n",
        "from classify import load, classify, encode\n",
        "output.clear()\n",
        "####################################\n",
        "####################################\n",
        "####################################\n",
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<canvas width=%d height=%d style=\"border-style:solid\"></canvas>\n",
        "<button>Finish</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "ctx.lineWidth = %d\n",
        "ctx.strokeStyle=\"#FFFFFF\";\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "from IPython.display import display\n",
        "words = \"airplane, cat, bee, chair, windmill\"#@param {\"type\":\"string\"}\n",
        "wordlist = words.split(\", \")\n",
        "load(wordlist)\n",
        "\n",
        "rounds = 5#@param\n",
        "canvas_size = \"512x512\"#@param {\"type\":\"string\"}\n",
        "sizes = canvas_size.split(\"x\")\n",
        "def draw(filename='drawing.png', w=int(sizes[0]), h=int(sizes[1]), line_width=2):\n",
        "  ht = HTML(canvas_html % (w, h, line_width))\n",
        "  display(ht)\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "close = [\"Woah!\", \"Nice!\", \"You Got It!\"]\n",
        "far = [\"So Close!\", \"Next Time!\", \"Almost!\"]\n",
        "\n",
        "urscore = 0\n",
        "for round in range(rounds):\n",
        "    thing = np.random.choice(wordlist)\n",
        "    if(round>0): print(\"CLIP Guessed {}\".format(wordlist[score.index(max(score))]))\n",
        "    print(\"Round {} | Your Score is.. {}\".format(round, urscore))\n",
        "    print(\"Draw A {} in the space below, and click Finish when you're done!\".format(thing))\n",
        "    draw()\n",
        "    score = classify(\"drawing.png\", return_raw=True)\n",
        "    \n",
        "    if(wordlist[score.index(max(score))]==thing):\n",
        "        print(np.random.choice(close))\n",
        "        urscore+=1\n",
        "    else:\n",
        "        print(np.random.choice(far))\n",
        "        urscore+=-1\n",
        "    output.clear()\n",
        "if(round>0): print(\"CLIP Guessed {}\".format(wordlist[score.index(max(score))]))\n",
        "print(\"Your final score is.. {} out of {}!\".format(urscore, rounds))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CLIP Guessed chair\n",
            "Your final score is.. -1 out of 5!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}